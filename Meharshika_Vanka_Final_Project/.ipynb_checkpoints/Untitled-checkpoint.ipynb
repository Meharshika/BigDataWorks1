{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def cluster_points(X, mu):\n",
    "    clusters  = {}\n",
    "    for x in X:\n",
    "        bestmukey = min([(i[0], np.linalg.norm(x-mu[i[0]])) \\\n",
    "                    for i in enumerate(mu)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[bestmukey].append(x)\n",
    "        except KeyError:\n",
    "            clusters[bestmukey] = [x]\n",
    "    return clusters\n",
    " \n",
    "def reevaluate_centers(mu, clusters):\n",
    "    newmu = []\n",
    "    keys = sorted(clusters.keys())\n",
    "    for k in keys:\n",
    "        newmu.append(np.mean(clusters[k], axis = 0))\n",
    "    return newmu\n",
    " \n",
    "def has_converged(mu, oldmu):\n",
    "    return (set([tuple(a) for a in mu]) == set([tuple(a) for a in oldmu]))\n",
    " \n",
    "\n",
    "def find_centers(X, K):\n",
    "    # Initialize to K random centers\n",
    "    oldmu = random.sample(X, K)\n",
    "    mu = random.sample(X, K)\n",
    "    while not has_converged(mu, oldmu):\n",
    "        oldmu = mu\n",
    "        # Assign all points in X to clusters\n",
    "        clusters = cluster_points(X, mu)\n",
    "        # Reevaluate centers\n",
    "        mu = reevaluate_centers(oldmu, clusters)\n",
    "    return(mu, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 2 iterations\n",
      " Cluster:  0 \t Point : [89.96414655004223, 18.38519860018839]\n",
      " Cluster:  0 \t Point : [35.23550391919492, 36.85302554728449]\n",
      " Cluster:  0 \t Point : [53.493855329763676, 8.045527560869248]\n",
      " Cluster:  1 \t Point : [104.40858864345768, 165.83245625564297]\n",
      " Cluster:  1 \t Point : [119.90939649593165, 123.2629442611433]\n",
      " Cluster:  1 \t Point : [81.48866152480238, 132.0061421383687]\n",
      " Cluster:  1 \t Point : [3.1806701793372527, 131.7165815542929]\n",
      " Cluster:  2 \t Point : [170.95244759557318, 49.757635765189455]\n",
      " Cluster:  2 \t Point : [81.51323509110952, 52.47401430129912]\n",
      " Cluster:  2 \t Point : [92.62045700843697, 21.17508976902245]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import random\n",
    "import subprocess\n",
    "\n",
    "\"\"\"\n",
    "This is a pure Python implementation of the K-Means Clustering algorithmn. The\n",
    "original can be found here:\n",
    "http://pandoricweb.tumblr.com/post/8646701677/python-implementation-of-the-k-means-clustering\n",
    "I have refactored the code and added comments to aid in readability.\n",
    "After reading through this code you should understand clearly how K-means works.\n",
    "If not, feel free to email me with questions and suggestions. (iandanforth at\n",
    "gmail)\n",
    "This script specifically avoids using numpy or other more obscure libraries. It\n",
    "is meant to be *clear* not fast.\n",
    "I have also added integration with the plot.ly plotting service. If you put in\n",
    "your (free) plot.ly credentials below, it will automatically plot the discovered\n",
    "clusters and their centroids.\n",
    "To use plotly integration you will need to:\n",
    "1. Get a username/key from www.plot.ly/api and enter them below\n",
    "2. Install the plotly module: pip install plotly\n",
    "\"\"\"\n",
    "\n",
    "PLOTLY_USERNAME = None\n",
    "PLOTLY_KEY = None\n",
    "\n",
    "if PLOTLY_USERNAME:\n",
    "    from plotly import plotly\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # How many points are in our dataset?\n",
    "    num_points = 10\n",
    "    \n",
    "    # For each of those points how many dimensions do they have?\n",
    "    dimensions = 2\n",
    "    \n",
    "    # Bounds for the values of those points in each dimension\n",
    "    lower = 0\n",
    "    upper = 200\n",
    "    \n",
    "    # The K in k-means. How many clusters do we assume exist?\n",
    "    num_clusters = 4\n",
    "    \n",
    "    # When do we say the optimization has 'converged' and stop updating clusters\n",
    "    opt_cutoff = 0.5\n",
    "    \n",
    "    # Generate some points\n",
    "    points = [makeRandomPoint(dimensions, lower, upper) for i in xrange(num_points)]\n",
    "    \n",
    "    # Cluster those data!\n",
    "    clusters = kmeans(points, num_clusters, opt_cutoff)\n",
    "\n",
    "    # Print our clusters\n",
    "    for i,c in enumerate(clusters):\n",
    "        for p in c.points:\n",
    "            print \" Cluster: \", i, \"\\t Point :\", p\n",
    "    \n",
    "    # Display clusters using plotly for 2d data\n",
    "    # This uses the 'open' command on a URL and may only work on OSX.\n",
    "    if dimensions == 2 and PLOTLY_USERNAME:\n",
    "        print \"Plotting points, launching browser ...\"\n",
    "        plotClusters(clusters)\n",
    "\n",
    "class Point:\n",
    "    '''\n",
    "    An point in n dimensional space\n",
    "    '''\n",
    "    def __init__(self, coords):\n",
    "        '''\n",
    "        coords - A list of values, one per dimension\n",
    "        '''\n",
    "        \n",
    "        self.coords = coords\n",
    "        self.n = len(coords)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.coords)\n",
    "\n",
    "class Cluster:\n",
    "    '''\n",
    "    A set of points and their centroid\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, points):\n",
    "        '''\n",
    "        points - A list of point objects\n",
    "        '''\n",
    "        \n",
    "        if len(points) == 0: raise Exception(\"ILLEGAL: empty cluster\")\n",
    "        # The points that belong to this cluster\n",
    "        self.points = points\n",
    "        \n",
    "        # The dimensionality of the points in this cluster\n",
    "        self.n = points[0].n\n",
    "        \n",
    "        # Assert that all points are of the same dimensionality\n",
    "        for p in points:\n",
    "            if p.n != self.n: raise Exception(\"ILLEGAL: wrong dimensions\")\n",
    "            \n",
    "        # Set up the initial centroid (this is usually based off one point)\n",
    "        self.centroid = self.calculateCentroid()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "        String representation of this object\n",
    "        '''\n",
    "        return str(self.points)\n",
    "    \n",
    "    def update(self, points):\n",
    "        '''\n",
    "        Returns the distance between the previous centroid and the new after\n",
    "        recalculating and storing the new centroid.\n",
    "        '''\n",
    "        old_centroid = self.centroid\n",
    "        self.points = points\n",
    "        self.centroid = self.calculateCentroid()\n",
    "        shift = getDistance(old_centroid, self.centroid) \n",
    "        return shift\n",
    "    \n",
    "    def calculateCentroid(self):\n",
    "        '''\n",
    "        Finds a virtual center point for a group of n-dimensional points\n",
    "        '''\n",
    "        numPoints = len(self.points)\n",
    "        # Get a list of all coordinates in this cluster\n",
    "        coords = [p.coords for p in self.points]\n",
    "        # Reformat that so all x's are together, all y'z etc.\n",
    "        unzipped = zip(*coords)\n",
    "        # Calculate the mean for each dimension\n",
    "        centroid_coords = [math.fsum(dList)/numPoints for dList in unzipped]\n",
    "        \n",
    "        return Point(centroid_coords)\n",
    "\n",
    "def kmeans(points, k, cutoff):\n",
    "    \n",
    "    # Pick out k random points to use as our initial centroids\n",
    "    initial = random.sample(points, k)\n",
    "    \n",
    "    # Create k clusters using those centroids\n",
    "    clusters = [Cluster([p]) for p in initial]\n",
    "    \n",
    "    # Loop through the dataset until the clusters stabilize\n",
    "    loopCounter = 0\n",
    "    while True:\n",
    "        # Create a list of lists to hold the points in each cluster\n",
    "        lists = [ [] for c in clusters]\n",
    "        clusterCount = len(clusters)\n",
    "        \n",
    "        # Start counting loops\n",
    "        loopCounter += 1\n",
    "        # For every point in the dataset ...\n",
    "        for p in points:\n",
    "            # Get the distance between that point and the centroid of the first\n",
    "            # cluster.\n",
    "            smallest_distance = getDistance(p, clusters[0].centroid)\n",
    "        \n",
    "            # Set the cluster this point belongs to\n",
    "            clusterIndex = 0\n",
    "        \n",
    "            # For the remainder of the clusters ...\n",
    "            for i in range(clusterCount - 1):\n",
    "                # calculate the distance of that point to each other cluster's\n",
    "                # centroid.\n",
    "                distance = getDistance(p, clusters[i+1].centroid)\n",
    "                # If it's closer to that cluster's centroid update what we\n",
    "                # think the smallest distance is, and set the point to belong\n",
    "                # to that cluster\n",
    "                if distance < smallest_distance:\n",
    "                    smallest_distance = distance\n",
    "                    clusterIndex = i+1\n",
    "            lists[clusterIndex].append(p)\n",
    "        \n",
    "        # Set our biggest_shift to zero for this iteration\n",
    "        biggest_shift = 0.0\n",
    "        \n",
    "        # As many times as there are clusters ...\n",
    "        for i in range(clusterCount):\n",
    "            # Calculate how far the centroid moved in this iteration\n",
    "            shift = clusters[i].update(lists[i])\n",
    "            # Keep track of the largest move from all cluster centroid updates\n",
    "            biggest_shift = max(biggest_shift, shift)\n",
    "        \n",
    "        # If the centroids have stopped moving much, say we're done!\n",
    "        if biggest_shift < cutoff:\n",
    "            print \"Converged after %s iterations\" % loopCounter\n",
    "            break\n",
    "    return clusters\n",
    "\n",
    "def getDistance(a, b):\n",
    "    '''\n",
    "    Euclidean distance between two n-dimensional points.\n",
    "    Note: This can be very slow and does not scale well\n",
    "    '''\n",
    "    if a.n != b.n:\n",
    "        raise Exception(\"ILLEGAL: non comparable points\")\n",
    "    \n",
    "    ret = reduce(lambda x,y: x + pow((a.coords[y]-b.coords[y]), 2),range(a.n),0.0)\n",
    "    return math.sqrt(ret)\n",
    "\n",
    "def makeRandomPoint(n, lower, upper):\n",
    "    '''\n",
    "    Returns a Point object with n dimensions and values between lower and\n",
    "    upper in each of those dimensions\n",
    "    '''\n",
    "    p = Point([random.uniform(lower, upper) for i in range(n)])\n",
    "    return p\n",
    "\n",
    "def plotClusters(data):\n",
    "    '''\n",
    "    Use the plotly API to plot data from clusters.\n",
    "    \n",
    "    Gets a plot URL from plotly and then uses subprocess to 'open' that URL\n",
    "    from the command line. This should open your default web browser.\n",
    "    '''\n",
    "    \n",
    "    # List of symbols each cluster will be displayed using    \n",
    "    symbols = ['circle', 'cross', 'triangle-up', 'square']\n",
    "\n",
    "    # Convert data into plotly format.\n",
    "    traceList = []\n",
    "    for i, c in enumerate(data):\n",
    "        data = []\n",
    "        for p in c.points:\n",
    "            data.append(p.coords)\n",
    "        # Data\n",
    "        trace = {}\n",
    "        trace['x'], trace['y'] = zip(*data)\n",
    "        trace['marker'] = {}\n",
    "        trace['marker']['symbol'] = symbols[i]\n",
    "        trace['name'] = \"Cluster \" + str(i)\n",
    "        traceList.append(trace)\n",
    "        # Centroid (A trace of length 1)\n",
    "        centroid = {}\n",
    "        centroid['x'] = [c.centroid.coords[0]]\n",
    "        centroid['y'] = [c.centroid.coords[1]]\n",
    "        centroid['marker'] = {}\n",
    "        centroid['marker']['symbol'] = symbols[i]\n",
    "        centroid['marker']['color'] = 'rgb(200,10,10)'\n",
    "        centroid['name'] = \"Centroid \" + str(i)\n",
    "        traceList.append(centroid)\n",
    "    \n",
    "    # Log in to plotly\n",
    "    py = plotly(username=PLOTLY_USERNAME, key=PLOTLY_KEY)\n",
    "\n",
    "    # Style the chart\n",
    "    datastyle = {'mode':'markers',\n",
    "             'type':'scatter',\n",
    "             'marker':{'line':{'width':0},\n",
    "                       'size':12,\n",
    "                       'opacity':0.6,\n",
    "                       'color':'rgb(74, 134, 232)'}}\n",
    "    \n",
    "    resp = py.plot(*traceList, style = datastyle)\n",
    "    \n",
    "    # Display that plot in a browser\n",
    "    cmd = \"open \" + resp['url']\n",
    "    subprocess.call(cmd, shell=True)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: Violation Date",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bb3a790706c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mdata_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mmeal_name_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: Violation Date"
     ]
    }
   ],
   "source": [
    "from pylab            import plot,show\n",
    "from numpy            import vstack,array\n",
    "from numpy.random     import rand\n",
    "from scipy.cluster.vq import kmeans, vq, whiten\n",
    "\n",
    "import csv\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # clusters\n",
    "    K = 3\n",
    "\n",
    "    data_arr = []\n",
    "    meal_name_arr = []\n",
    "\n",
    "    with open(.csv', 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            data_arr.append([float(x) for x in row[1:]])\n",
    "            meal_name_arr.append([row[0]])\n",
    "\n",
    "    data = vstack( data_arr )\n",
    "    meal_name = vstack(meal_name_arr)\n",
    "\n",
    "    # normalization\n",
    "    data = whiten(data)\n",
    "\n",
    "    # computing K-Means with K (clusters)\n",
    "    centroids, distortion = kmeans(data,3)\n",
    "    print \"distortion = \" + str(distortion)\n",
    "\n",
    "    # assign each sample to a cluster\n",
    "    idx,_ = vq(data,centroids)\n",
    "\n",
    "    # some plotting using numpy's logical indexing\n",
    "    plot(data[idx==0,0], data[idx==0,1],'ob',\n",
    "         data[idx==1,0], data[idx==1,1],'or',\n",
    "         data[idx==2,0], data[idx==2,1],'og')\n",
    "\n",
    "    print meal_name\n",
    "    print data\n",
    "\n",
    "    for i in range(K):\n",
    "        result_names = meal_name[idx==i, 0]\n",
    "        print \"=================================\"\n",
    "        print \"Cluster \" + str(i+1)\n",
    "        for name in result_names:\n",
    "            print name\n",
    "\n",
    "    plot(centroids[:,0],\n",
    "         centroids[:,1],\n",
    "         'sg',markersize=8)\n",
    "\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# kmeans clustering algorithm\n",
    "# data = set of data points\n",
    "# k = number of clusters\n",
    "# c = initial list of centroids (if provided)\n",
    "#\n",
    "def kmeans(data, k, c):\n",
    "    centroids = []\n",
    "\n",
    "    centroids = randomize_centroids(data, centroids, k)  \n",
    "\n",
    "    old_centroids = [[] for i in range(k)] \n",
    "\n",
    "    iterations = 0\n",
    "    while not (has_converged(centroids, old_centroids, iterations)):\n",
    "        iterations += 1\n",
    "\n",
    "        clusters = [[] for i in range(k)]\n",
    "\n",
    "        # assign data points to clusters\n",
    "        clusters = euclidean_dist(data, centroids, clusters)\n",
    "\n",
    "        # recalculate centroids\n",
    "        index = 0\n",
    "        for cluster in clusters:\n",
    "            old_centroids[index] = centroids[index]\n",
    "            centroids[index] = np.mean(cluster, axis=0).tolist()\n",
    "            index += 1\n",
    "\n",
    "\n",
    "    print(\"The total number of data instances is: \" + str(len(data)))\n",
    "    print(\"The total number of iterations necessary is: \" + str(iterations))\n",
    "    print(\"The means of each cluster are: \" + str(centroids))\n",
    "    print(\"The clusters are as follows:\")\n",
    "    for cluster in clusters:\n",
    "        print(\"Cluster with a size of \" + str(len(cluster)) + \" starts here:\")\n",
    "        print(np.array(cluster).tolist())\n",
    "        print(\"Cluster ends here.\")\n",
    "\n",
    "    return\n",
    "\n",
    "# Calculates euclidean distance between\n",
    "# a data point and all the available cluster\n",
    "# centroids.      \n",
    "def euclidean_dist(data, centroids, clusters):\n",
    "    for instance in data:  \n",
    "        # Find which centroid is the closest\n",
    "        # to the given data point.\n",
    "        mu_index = min([(i[0], np.linalg.norm(instance-centroids[i[0]])) \\\n",
    "                            for i in enumerate(centroids)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[mu_index].append(instance)\n",
    "        except KeyError:\n",
    "            clusters[mu_index] = [instance]\n",
    "\n",
    "    # If any cluster is empty then assign one point\n",
    "    # from data set randomly so as to not have empty\n",
    "    # clusters and 0 means.        \n",
    "    for cluster in clusters:\n",
    "        if not cluster:\n",
    "            cluster.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# randomize initial centroids\n",
    "def randomize_centroids(data, centroids, k):\n",
    "    for cluster in range(0, k):\n",
    "        centroids.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# check if clusters have converged    \n",
    "def has_converged(centroids, old_centroids, iterations):\n",
    "    MAX_ITERATIONS = 1000\n",
    "    if iterations > MAX_ITERATIONS:\n",
    "        return True\n",
    "    return old_centroids == centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  1.]\n",
      " [ 0.  0.]\n",
      " [ 1.  0.]]\n",
      "1\n",
      "11\n",
      "\n",
      "--------Centers of the four different clusters--------\n",
      "Time\t Cent1\t Cent2\n",
      "1 \t 0.0 \t 0.0\n",
      "2 \t 0.0 \t 0.0\n",
      "3 \t 0.0 \t 0.0\n",
      "4 \t 0.0 \t 0.0\n",
      "5 \t 0.0 \t 0.0\n",
      "6 \t 0.0 \t 0.0\n",
      "7 \t 0.0 \t 0.0\n",
      "8 \t 0.0 \t 0.0\n",
      "9 \t 0.0 \t 0.0\n",
      "10 \t 0.0 \t 1.0\n",
      "11 \t 1.0 \t 1.0\n",
      "12 \t 1.0 \t 0.0\n",
      "13 \t 1.0 \t 0.0\n",
      "14 \t 1.0 \t 0.0\n",
      "15 \t 1.0 \t 1.0\n",
      "16 \t 0.0 \t 0.0\n",
      "17 \t 0.0 \t 1.0\n",
      "\n",
      "--------Which cluster each county is in--------\n",
      "County         \tCluster\n",
      "MANHATTAN      \t2\n",
      "QUEENS         \t1\n",
      "\n",
      "-----How many of each deal involve a customer in each cluster-----\n",
      "Time\t Clust1\t Clust2\n",
      "1 \t0 \t0 \t\n",
      "2 \t0 \t0 \t\n",
      "3 \t0 \t0 \t\n",
      "4 \t0 \t0 \t\n",
      "5 \t0 \t0 \t\n",
      "6 \t0 \t0 \t\n",
      "7 \t0 \t0 \t\n",
      "8 \t0 \t0 \t\n",
      "9 \t0 \t0 \t\n",
      "10 \t0 \t1 \t\n",
      "11 \t1 \t1 \t\n",
      "12 \t1 \t0 \t\n",
      "13 \t1 \t0 \t\n",
      "14 \t1 \t0 \t\n",
      "15 \t1 \t1 \t\n",
      "16 \t0 \t0 \t\n",
      "17 \t0 \t1 \t\n",
      "\n",
      "The total distance of the solution found is 0.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "A program to carry out Kmeans clustering where K=4\n",
    "on data relating to wine marketing from book \n",
    "\"Data Smart: Using Data Science to Transform Information into Insight\"\n",
    "\n",
    "Requires csv input file OfferInfo.csv with headings\n",
    "'Campaign', 'Varietal', 'Minimum Qty (kg)', 'Discount (%)', 'Origin', 'Past Peak'\n",
    "and input file Transactions.csv with headings\n",
    "'Customer Last Name', 'Offer #'\n",
    "\"\"\"\n",
    "\n",
    "#make more similar to Python 3\n",
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "\n",
    "#other stuff we need to import\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "\n",
    "#beginning of main program\n",
    "\n",
    "#read in OfferInfo.csv\n",
    "csvf = open('EcbNoticeofViolations.csv','rU')\n",
    "rows = csv.reader(csvf)\n",
    "ecb_sheet = [row for row in rows]\n",
    "#print (ecb_sheet)\n",
    "csvf.close()\n",
    "\n",
    "#read in Transactions.csv\n",
    "csvf = open('ParkingViolations.csv','rU')\n",
    "rows = csv.reader(csvf)\n",
    "parking_sheet = [row for row in rows]\n",
    "#print (parking_sheet)\n",
    "csvf.close()\n",
    "\n",
    "#converting time to secs\n",
    "def get_sec(s):\n",
    "    l = s.split(':')\n",
    "    return int(l[0]) \n",
    "\n",
    "#first row of each spreadsheet is column headings, so we remove them\n",
    "ecb_sheet_data = ecb_sheet[1:]\n",
    "parking_sheet_data = parking_sheet[1:]\n",
    "#print (ecb_sheet_data)\n",
    "#print (parking_sheet_data)\n",
    "\n",
    "\n",
    "K=2 #five clusters\n",
    "num_times = len(ecb_sheet) #assume listed offers are distinct\n",
    "#print (num_times)\n",
    "\n",
    "#find the sorted list of customer last names\n",
    "county_names = []\n",
    "for row in ecb_sheet_data:\n",
    "    county_names.append(row[4])\n",
    "county_names = list(set(county_names))\n",
    "x=county_names.sort()\n",
    "#print (county_names)\n",
    "num_counties = len(county_names)\n",
    "\n",
    "#times = []\n",
    "#for row in ecb_sheet_data:\n",
    " #   times.append(row[2])\n",
    "#times = list(set(times))\n",
    "#num_times = len(times)\n",
    "#print (num_times)\n",
    "\n",
    "#create a num_deals x num_customers matrix of which customer took which deal\n",
    "county_time_matrix = np.zeros((num_times,num_counties))\n",
    "for row in ecb_sheet_data:\n",
    "    county_number = county_names.index(row[4])\n",
    "    #print (range(county_number))\n",
    "    #time_secs = ecb_sheet_data(row[2])\n",
    "    #time_num = get_sec(time_secs)\n",
    "    time_number = int(get_sec(row[2]))\n",
    "    #print (time_number)\n",
    "    county_time_matrix[time_number-1,county_number] = 1\n",
    "time_county_matrix = county_time_matrix.transpose()\n",
    "print (county_time_matrix)\n",
    "print (county_number)\n",
    "print (time_number)\n",
    "\n",
    "#initialize and carry out clustering\n",
    "km = KMeans(n_clusters = K)\n",
    "km.fit(time_county_matrix)\n",
    "\n",
    "#find center of clusters\n",
    "centers = km.cluster_centers_\n",
    "centers[centers<0] = 0 #the minimization function may find very small negative numbers, we threshold them to 0\n",
    "centers = centers.round(2)\n",
    "print('\\n--------Centers of the four different clusters--------')\n",
    "print('Time\\t Cent1\\t Cent2')\n",
    "for i in range(num_times):\n",
    "    print(i+1,'\\t',centers[0,i],'\\t',centers[1,i])\n",
    "\n",
    "\n",
    "#find which cluster each customer is in\n",
    "prediction = km.predict(time_county_matrix)\n",
    "#print (prediction)\n",
    "print('\\n--------Which cluster each county is in--------')\n",
    "print('{:<15}\\t{}'.format('County','Cluster'))\n",
    "for i in range(len(prediction)):\n",
    "    #print (len(prediction))\n",
    "    print('{:<15}\\t{}'.format(county_names[i],prediction[i]+1))\n",
    "    \n",
    "#determine which deals are most often in each cluster\n",
    "county_cluster_matrix = np.zeros((num_times,K),dtype=np.int)\n",
    "print('\\n-----How many of each deal involve a customer in each cluster-----')\n",
    "print('Time\\t Clust1\\t Clust2')            \n",
    "for i in range(num_times):\n",
    "    for j in range(num_counties):\n",
    "        if county_time_matrix[i,j] == 1:\n",
    "            county_cluster_matrix[i,prediction[j]] += 1\n",
    "\n",
    "for i in range(num_times):\n",
    "    print(i+1,'\\t',end='')\n",
    "    for j in range(K):\n",
    "        print(county_cluster_matrix[i,j],'\\t',end='')\n",
    "    print()\n",
    "print()\n",
    "\n",
    "print('The total distance of the solution found is',sum((km.transform(time_county_matrix)).min(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Centers of the four different clusters--------\n",
      "Deal\t Cent1\t Cent2\t Cent3\t Cent4\n",
      "1 \t 0.0 \t 0.0 \t 0.0 \t 1.0\n",
      "2 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "3 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "4 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "5 \t 0.0 \t 0.0 \t 0.0 \t 1.0\n",
      "6 \t 1.0 \t 0.0 \t 0.0 \t 0.0\n",
      "7 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "8 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "9 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "10 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "11 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "12 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "13 \t 1.0 \t 0.0 \t 0.0 \t 0.0\n",
      "14 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "15 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "16 \t 0.0 \t 0.14 \t 0.0 \t 0.0\n",
      "[0 1 1 1 1 3 1 2 1 1]\n",
      "\n",
      "--------Which cluster each customer is in--------\n",
      "Time           \tCluster\n",
      "10:03:00       \t1\n",
      "11:13:00       \t2\n",
      "11:45:00       \t2\n",
      "12:29:00       \t2\n",
      "13:30:00       \t2\n",
      "13:53:00       \t4\n",
      "14:45:00       \t2\n",
      "15:06:00       \t3\n",
      "15:39:00       \t2\n",
      "17:38:00       \t2\n",
      "\n",
      "-----How many of each deal involve a customer in each cluster-----\n",
      "Time\t Clust1\t Clust2\t Clust3\t Clust4\n",
      "1 \t0 \t0 \t0 \t1 \t\n",
      "2 \t0 \t0 \t1 \t0 \t\n",
      "3 \t0 \t1 \t0 \t0 \t\n",
      "4 \t0 \t1 \t0 \t0 \t\n",
      "5 \t0 \t0 \t0 \t1 \t\n",
      "6 \t1 \t0 \t0 \t0 \t\n",
      "7 \t0 \t0 \t1 \t0 \t\n",
      "8 \t0 \t1 \t0 \t0 \t\n",
      "9 \t0 \t0 \t1 \t0 \t\n",
      "10 \t0 \t1 \t0 \t0 \t\n",
      "11 \t0 \t1 \t0 \t0 \t\n",
      "12 \t0 \t1 \t0 \t0 \t\n",
      "13 \t1 \t0 \t0 \t0 \t\n",
      "14 \t0 \t1 \t0 \t0 \t\n",
      "15 \t0 \t0 \t1 \t0 \t\n",
      "16 \t0 \t1 \t0 \t0 \t\n",
      "\n",
      "The total distance of the solution found is 6.88234171602\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "A program to carry out Kmeans clustering where K=4\n",
    "on data relating to wine marketing from book \n",
    "\"Data Smart: Using Data Science to Transform Information into Insight\"\n",
    "\n",
    "Requires csv input file OfferInfo.csv with headings\n",
    "'Campaign', 'Varietal', 'Minimum Qty (kg)', 'Discount (%)', 'Origin', 'Past Peak'\n",
    "and input file Transactions.csv with headings\n",
    "'Customer Last Name', 'Offer #'\n",
    "\"\"\"\n",
    "\n",
    "#make more similar to Python 3\n",
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "\n",
    "#other stuff we need to import\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#beginning of main program\n",
    "\n",
    "#read in OfferInfo.csv\n",
    "csvf = open('EcbNoticeofViolations.csv','rU')\n",
    "rows = csv.reader(csvf)\n",
    "ecb_sheet = [row for row in rows]\n",
    "csvf.close()\n",
    "\n",
    "#read in Transactions.csv\n",
    "#csvf = open('Transactions.csv','rU')\n",
    "#rows = csv.reader(csvf)\n",
    "#transaction_sheet = [row for row in rows]\n",
    "#csvf.close()\n",
    "\n",
    "#first row of each spreadsheet is column headings, so we remove them\n",
    "ecb_sheet_data = ecb_sheet[1:]\n",
    "#print (ecb_sheet_data)\n",
    "#transaction_sheet_data = transaction_sheet[1:]\n",
    "\n",
    "K=4 #four clusters\n",
    "#num_tickets = len(ecb_sheet_data) #assume listed offers are distinct\n",
    "\n",
    "#find the sorted list of customer last names\n",
    "times = []\n",
    "tickets = []\n",
    "for row in ecb_sheet_data:\n",
    "    tickets.append(row[0])\n",
    "    times.append(row[2])\n",
    "tickets = list(set(tickets))\n",
    "times = list(set(times))\n",
    "#print (times)\n",
    "#print (tickets)\n",
    "times.sort()\n",
    "num_times = len(times)\n",
    "\n",
    "#create a num_deals x num_customers matrix of which customer took which deal\n",
    "ticket_time_matrix = np.zeros((num_tickets,num_times))\n",
    "for row in ecb_sheet_data:\n",
    "    time_number = times.index(row[2])\n",
    "    ticket_number = tickets.index(row[0])\n",
    "    ticket_time_matrix[ticket_number-1,time_number] = 1\n",
    "time_ticket_matrix = ticket_time_matrix.transpose()\n",
    "\n",
    "#initialize and carry out clustering\n",
    "km = KMeans(n_clusters = K)\n",
    "km.fit(time_ticket_matrix)\n",
    "\n",
    "#find center of clusters\n",
    "centers = km.cluster_centers_\n",
    "centers[centers<0] = 0 #the minimization function may find very small negative numbers, we threshold them to 0\n",
    "centers = centers.round(2)\n",
    "print('\\n--------Centers of the four different clusters--------')\n",
    "print('Deal\\t Cent1\\t Cent2\\t Cent3\\t Cent4')\n",
    "for i in range(num_tickets):\n",
    "    print(i+1,'\\t',centers[0,i],'\\t',centers[1,i],'\\t',centers[2,i],'\\t',centers[3,i])\n",
    "\n",
    "#find which cluster each customer is in\n",
    "prediction = km.predict(time_ticket_matrix)\n",
    "print(prediction)\n",
    "print('\\n--------Which cluster each customer is in--------')\n",
    "print('{:<15}\\t{}'.format('Time','Cluster'))\n",
    "for i in range(len(prediction)):\n",
    "    print('{:<15}\\t{}'.format(times[i],prediction[i]+1))\n",
    "    \n",
    "\n",
    "#determine which deals are most often in each cluster\n",
    "time_cluster_matrix = np.zeros((num_tickets,K),dtype=np.int)\n",
    "print('\\n-----How many of each deal involve a customer in each cluster-----')\n",
    "print('Time\\t Clust1\\t Clust2\\t Clust3\\t Clust4')            \n",
    "for i in range(num_tickets):\n",
    "    for j in range(num_times):\n",
    "        if ticket_time_matrix[i,j] == 1:\n",
    "            time_cluster_matrix[i,prediction[j]] += 1\n",
    "\n",
    "for i in range(num_tickets):\n",
    "    print(i+1,'\\t',end='')\n",
    "    for j in range(K):\n",
    "        print(time_cluster_matrix[i,j],'\\t',end='')\n",
    "    print()\n",
    "print()\n",
    "\n",
    "print('The total distance of the solution found is',sum((km.transform(time_ticket_matrix)).min(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      "--------Centers of the four different clusters--------\n",
      "Deal\t Cent1\t Cent2\t Cent3\t Cent4\n",
      "1 \t 0.0 \t 0.0 \t 0.0 \t 1.0\n",
      "2 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "3 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "4 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "5 \t 0.0 \t 0.0 \t 0.0 \t 1.0\n",
      "6 \t 0.0 \t 1.0 \t 0.0 \t 0.0\n",
      "7 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "8 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "9 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "10 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "11 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "12 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "13 \t 0.0 \t 1.0 \t 0.0 \t 0.0\n",
      "14 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "15 \t 0.0 \t 0.0 \t 1.0 \t 0.0\n",
      "16 \t 0.14 \t 0.0 \t 0.0 \t 0.0\n",
      "[1 0 0 0 0 3 0 2 0 0]\n",
      "\n",
      "--------Which cluster each customer is in--------\n",
      "Time           \tCluster\n",
      "10:03:00       \t2\n",
      "11:13:00       \t1\n",
      "11:45:00       \t1\n",
      "12:29:00       \t1\n",
      "13:30:00       \t1\n",
      "13:53:00       \t4\n",
      "14:45:00       \t1\n",
      "15:06:00       \t3\n",
      "15:39:00       \t1\n",
      "17:38:00       \t1\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "A program to carry out Kmeans clustering where K=4\n",
    "on data relating to wine marketing from book \n",
    "\"Data Smart: Using Data Science to Transform Information into Insight\"\n",
    "\n",
    "Requires csv input file OfferInfo.csv with headings\n",
    "'Campaign', 'Varietal', 'Minimum Qty (kg)', 'Discount (%)', 'Origin', 'Past Peak'\n",
    "and input file Transactions.csv with headings\n",
    "'Customer Last Name', 'Offer #'\n",
    "\"\"\"\n",
    "\n",
    "#make more similar to Python 3\n",
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "\n",
    "#other stuff we need to import\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#beginning of main program\n",
    "\n",
    "#read in OfferInfo.csv\n",
    "csvf = open('EcbNoticeofViolations.csv','rU')\n",
    "rows = csv.reader(csvf)\n",
    "ecb_sheet = [row for row in rows]\n",
    "csvf.close()\n",
    "\n",
    "#read in Transactions.csv\n",
    "#csvf = open('Transactions.csv','rU')\n",
    "#rows = csv.reader(csvf)\n",
    "#transaction_sheet = [row for row in rows]\n",
    "#csvf.close()\n",
    "\n",
    "#first row of each spreadsheet is column headings, so we remove them\n",
    "ecb_sheet_data = ecb_sheet[1:]\n",
    "#print (ecb_sheet_data)\n",
    "#transaction_sheet_data = transaction_sheet[1:]\n",
    "\n",
    "K=4 #four clusters\n",
    "#num_tickets = len(ecb_sheet_data) #assume listed offers are distinct\n",
    "\n",
    "#find the sorted list of customer last names\n",
    "times = []\n",
    "tickets = []\n",
    "for row in ecb_sheet_data:\n",
    "    tickets.append(row[0])\n",
    "    times.append(row[2])\n",
    "tickets = list(set(tickets))\n",
    "times = list(set(times))\n",
    "#print (times)\n",
    "#print (tickets)\n",
    "times.sort()\n",
    "num_times = len(times)\n",
    "\n",
    "#create a num_deals x num_customers matrix of which customer took which deal\n",
    "ticket_time_matrix = np.zeros((num_tickets,num_times))\n",
    "for row in ecb_sheet_data:\n",
    "    time_number = times.index(row[2])\n",
    "    ticket_number = tickets.index(row[0])\n",
    "    ticket_time_matrix[ticket_number-1,time_number] = 1\n",
    "time_ticket_matrix = ticket_time_matrix.transpose()\n",
    "print (time_ticket_matrix)\n",
    "\n",
    "#initialize and carry out clustering\n",
    "km = KMeans(n_clusters = K)\n",
    "km.fit(time_ticket_matrix)\n",
    "\n",
    "#find center of clusters\n",
    "centers = km.cluster_centers_\n",
    "centers[centers<0] = 0 #the minimization function may find very small negative numbers, we threshold them to 0\n",
    "centers = centers.round(2)\n",
    "print('\\n--------Centers of the four different clusters--------')\n",
    "print('Deal\\t Cent1\\t Cent2\\t Cent3\\t Cent4')\n",
    "for i in range(num_tickets):\n",
    "    print(i+1,'\\t',centers[0,i],'\\t',centers[1,i],'\\t',centers[2,i],'\\t',centers[3,i])\n",
    "\n",
    "#find which cluster each customer is in\n",
    "prediction = km.predict(time_ticket_matrix)\n",
    "print(prediction)\n",
    "print('\\n--------Which cluster each customer is in--------')\n",
    "print('{:<15}\\t{}'.format('Time','Cluster'))\n",
    "for i in range(len(prediction)):\n",
    "    print('{:<15}\\t{}'.format(times[i],prediction[i]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-48bc69428919>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mcounty_time_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_countys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mecb_sheet_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mcounty_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mcounty_time_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounty_number\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_number\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "A program to carry out Kmeans clustering where K=4\n",
    "on data relating to wine marketing from book \n",
    "\"Data Smart: Using Data Science to Transform Information into Insight\"\n",
    "\n",
    "Requires csv input file OfferInfo.csv with headings\n",
    "'Campaign', 'Varietal', 'Minimum Qty (kg)', 'Discount (%)', 'Origin', 'Past Peak'\n",
    "and input file Transactions.csv with headings\n",
    "'Customer Last Name', 'Offer #'\n",
    "\"\"\"\n",
    "\n",
    "#make more similar to Python 3\n",
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "\n",
    "#other stuff we need to import\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#beginning of main program\n",
    "\n",
    "#read in OfferInfo.csv\n",
    "csvf = open('ECB_Notice_of_Violations-3.csv','rU')\n",
    "rows = csv.reader(csvf)\n",
    "ecb_sheet = [row for row in rows]\n",
    "csvf.close()\n",
    "\n",
    "#read in Transactions.csv\n",
    "#csvf = open('Transactions.csv','rU')\n",
    "#rows = csv.reader(csvf)\n",
    "#transaction_sheet = [row for row in rows]\n",
    "#csvf.close()\n",
    "\n",
    "#first row of each spreadsheet is column headings, so we remove them\n",
    "ecb_sheet_data = ecb_sheet[1:]\n",
    "#print (ecb_sheet_data)\n",
    "#transaction_sheet_data = transaction_sheet[1:]\n",
    "\n",
    "K=2 #four clusters\n",
    "#num_countys = len(ecb_sheet_data) #assume listed offers are distinct\n",
    "\n",
    "#find the sorted list of customer last names\n",
    "times = []\n",
    "countys = []\n",
    "for row in ecb_sheet_data:\n",
    "    countys.append(row[4])\n",
    "    times.append(row[2])\n",
    "countys = list(set(countys))\n",
    "times = list(set(times))\n",
    "#print (times)\n",
    "#print (countys)\n",
    "times.sort()\n",
    "num_times = len(times)\n",
    "num_countys = len(countys)\n",
    "\n",
    "#create a num_deals x num_customers matrix of which customer took which deal\n",
    "county_time_matrix = np.zeros((num_countys,num_times))\n",
    "for row in ecb_sheet_data:\n",
    "    time_number = times.index(row[2])\n",
    "    county_number = countys.index(row[4])\n",
    "    county_time_matrix[county_number-1,time_number] = 1\n",
    "time_county_matrix = county_time_matrix.transpose()\n",
    "print (time_county_matrix)\n",
    "\n",
    "#initialize and carry out clustering\n",
    "km = KMeans(n_clusters = K)\n",
    "km.fit(time_county_matrix)\n",
    "\n",
    "#find center of clusters\n",
    "centers = km.cluster_centers_\n",
    "centers[centers<0] = 0 #the minimization function may find very small negative numbers, we threshold them to 0\n",
    "centers = centers.round(2)\n",
    "print('\\n--------Centers of the four different clusters--------')\n",
    "print('Deal\\t Cent1\\t Cent2')\n",
    "for i in range(num_countys):\n",
    "    print(i+1,'\\t',centers[0,i],'\\t',centers[1,i])\n",
    "\n",
    "#find which cluster each customer is in\n",
    "prediction = km.predict(time_county_matrix)\n",
    "print(prediction)\n",
    "print('\\n--------Which cluster each customer is in--------')\n",
    "print('{:<15}\\t{}'.format('Time','Cluster'))\n",
    "for i in range(len(prediction)):\n",
    "    print('{:<15}\\t{}'.format(times[i],prediction[i]+1))\n",
    "\n",
    "#determine which deals are most often in each cluster\n",
    "time_cluster_matrix = np.zeros((num_countys,K),dtype=np.int)\n",
    "print('\\n-----How many of each deal involve a customer in each cluster-----')\n",
    "print('County\\t Clust1\\t Clust2')            \n",
    "for i in range(num_countys):\n",
    "    for j in range(num_times):\n",
    "        if county_time_matrix[i,j] == 1:\n",
    "            time_cluster_matrix[i,prediction[j]] += 1\n",
    "\n",
    "for i in range(num_countys):\n",
    "    print(i+1,'\\t',end='')\n",
    "    for j in range(K):\n",
    "        print(time_cluster_matrix[i,j],'\\t',end='')\n",
    "    print()\n",
    "print()\n",
    "\n",
    "print('The total distance of the solution found is',sum((km.transform(time_county_matrix)).min(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
